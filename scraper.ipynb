{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scraper.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parasgulati8/Web-Scraper/blob/master/scraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSDQMc2zmTMR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from bs4 import BeautifulSoup as bs\n",
        "# import urllib3\n",
        "import requests\n",
        "# import json\n",
        "# from urllib.request import urlopen, urlretrieve, quote\n",
        "# from openpyxl import Workbook\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HMSsqemjhkig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Property Summary Page\n",
        "def get_property_summary(index):\n",
        "    print('fetching Property Summary for ', index)\n",
        "    url = 'http://www.padctn.org/prc/property/' + str(index) + '/card/1'\n",
        "    page = requests.get(url)\n",
        "    soup = bs(page.text, 'html.parser')\n",
        "    lists = soup.find_all('ul', attrs={'class':'att'})\n",
        "    table = dict()\n",
        "    for i in range(len(lists)):\n",
        "      lists[i] = lists[i].find_all('li')\n",
        "      lists[i] = [item.text for item in lists[i]]\n",
        "      lists[i] = [lists[i][j].split(': ') for j in range(len(lists[i]))]\n",
        "      for pair in lists[i]:\n",
        "        key , value = pair\n",
        "        table[key] = value\n",
        "    \n",
        "    index = 1\n",
        "    summary = pd.DataFrame(table, index=[index])\n",
        "    return summary\n",
        "\n",
        "# Historical data\n",
        "def get_historical_data(index):\n",
        "    print('fetching historical data for ', index)\n",
        "    url = 'http://www.padctn.org/prc/property/' + str(index) + '/card/1/historical'\n",
        "    page = requests.get(url)\n",
        "    soup = bs(page.text, 'html.parser')\n",
        "    parcel = soup.h2.text\n",
        "    parcel = ' '.join(parcel.split()[6:])\n",
        "    dfs = pd.read_html(requests.get(url,  headers={'User-agent': 'Mozilla/5.0'}).text,\n",
        "                          attrs={\"class\":\"table table-condensed table-bordered\"})\n",
        "    sales_history, previous_appraisals = dfs[0], dfs[1]\n",
        "    sales_history['Map & Parcel'] = [parcel]*len(sales_history)\n",
        "    sales_history['Property #'] = [index]*len(sales_history)\n",
        "    previous_appraisals['Map & Parcel'] = [parcel]*len(previous_appraisals)\n",
        "    previous_appraisals['Property #'] = [index]*len(previous_appraisals)\n",
        "    return sales_history, previous_appraisals, parcel\n",
        "                        \n",
        "\n",
        "# Building and Improvement Details Page\n",
        "def get_building_improvement(index, parcel):\n",
        "    print('fetching building improvement for ', index)\n",
        "    url = 'http://www.padctn.org/prc/property/' + str(index) + '/card/1/interior'\n",
        "    page = requests.get(url)\n",
        "    soup = bs(page.text, 'html.parser')\n",
        "    lists = (soup.find_all('ul', attrs={'class':'att'}))\n",
        "    table = dict()\n",
        "    for i in range(len(lists)):\n",
        "      lists[i] = lists[i].find_all('li')\n",
        "      lists[i] = [item.text for item in lists[i]]\n",
        "      lists[i] = [lists[i][j].split(': ') for j in range(len(lists[i]))]\n",
        "      for pair in lists[i]:\n",
        "        key , value = pair\n",
        "        table[key] = value\n",
        "    \n",
        "    temp_table = pd.DataFrame(table, index=[0])\n",
        "    temp_table['Map & Parcel'] = [parcel]\n",
        "    dfs = pd.read_html(requests.get(url,  headers={'User-agent': 'Mozilla/5.0'}).text)\n",
        "    building_footage, building_features = dfs[0], dfs[1]\n",
        "    building_features['Map & Parcel'] = [parcel]*(1 if len(building_features) == 0 else len(building_features))\n",
        "    building_footage['Map & Parcel'] = [parcel]*len(building_footage)\n",
        "    \n",
        "    merged = pd.merge(building_footage, building_features, on='Map & Parcel')\n",
        "    building_improvement = pd.merge(merged, temp_table, on='Map & Parcel')\n",
        "    return building_improvement\n",
        "\n",
        "def terminate(index):\n",
        "    for i in range(index+1,index+6):\n",
        "        temp_history, temp_appraisal = get_historical_data(i)\n",
        "        if (np.any(temp_history) or np.any(temp_appraisal)):                  \n",
        "            return False\n",
        "    return True\n",
        "\n",
        "property_summary = get_property_summary(1)\n",
        "sales_history, previous_appraisals, parcel = get_historical_data(1)\n",
        "building_improvement = get_building_improvement(1, parcel)\n",
        "\n",
        "\n",
        "index = 2\n",
        "patience = 0\n",
        "while True:\n",
        "      # Property Summary Page\n",
        "      try:\n",
        "        _property_summary =  get_property_summary(index)\n",
        "        if np.any(_property_summary):    \n",
        "          property_summary = pd.concat((property_summary, _property_summary))\n",
        "      except:\n",
        "        print('Exception occured in fetching Property Summary page for index', index)\n",
        "      \n",
        "      # Historical data\n",
        "      try:\n",
        "        _sales_history, _previous_appraisals, parcel = get_historical_data(index)\n",
        "        if np.any(_sales_history):\n",
        "            sales_history = pd.concat((sales_history, _sales_history))\n",
        "        if np.any(_previous_appraisals):\n",
        "            previous_appraisals = pd.concat((previous_appraisals, _previous_appraisals))\n",
        "      except:\n",
        "          print('Exception occured in fetching Sales History page for index', index)\n",
        "\n",
        "      # Building and Improvements Details\n",
        "      try:\n",
        "        _building_improvement = get_building_improvement(index, parcel)\n",
        "        if np.any(_building_improvement):\n",
        "            building_improvement = pd.concat((building_improvement, _building_improvement))\n",
        "      except:\n",
        "        print('Exception occured in fetching Building Improvement page for index', index)  \n",
        "      \n",
        "      if not (np.any(_sales_history) or np.any(_previous_appraisals)):\n",
        "          try:\n",
        "            end  = terminate(index)\n",
        "            print ('Checking to terminate')  \n",
        "            if end == True:\n",
        "                print('Scraping Ends. Last propert # scraped is', index)\n",
        "                print (_property_summary, _sales_history, _previous_appraisals, _building_improvement)\n",
        "                break\n",
        "          except:\n",
        "            print('Exception occured in checking termination for index', index)      \n",
        "            break\n",
        "          \n",
        "      print(index)\n",
        "      index = index+1\n",
        "      if index == 5:\n",
        "          break \n",
        "\n",
        "index = 2\n",
        "patience = 0\n",
        "while True:\n",
        "      # Property Summary Page\n",
        "      try:\n",
        "        _property_summary =  get_property_summary(index)\n",
        "        if np.any(_property_summary):    \n",
        "          property_summary = pd.concat((property_summary, _property_summary))\n",
        "      except:\n",
        "        print('Exception occured in fetching Property Summary page for index', index)\n",
        "      \n",
        "      # Historical data\n",
        "      try:\n",
        "        _sales_history, _previous_appraisals, parcel = get_historical_data(index)\n",
        "        if np.any(_sales_history):\n",
        "            sales_history = pd.concat((sales_history, _sales_history))\n",
        "        if np.any(_previous_appraisals):\n",
        "            previous_appraisals = pd.concat((previous_appraisals, _previous_appraisals))\n",
        "      except:\n",
        "          print('Exception occured in fetching Sales History page for index', index)\n",
        "\n",
        "      # Building and Improvements Details\n",
        "      try:\n",
        "        _building_improvement = get_building_improvement(index, parcel)\n",
        "        if np.any(_building_improvement):\n",
        "            building_improvement = pd.concat((building_improvement, _building_improvement))\n",
        "      except:\n",
        "        print('Exception occured in fetching Building Improvement page for index', index)  \n",
        "      \n",
        "      if not (np.any(_sales_history) or np.any(_previous_appraisals)):\n",
        "          try:\n",
        "            end  = terminate(index)\n",
        "            print ('Checking to terminate')  \n",
        "            if end == True:\n",
        "                print('Scraping Ends. Last propert # scraped is', index)\n",
        "                print (_property_summary, _sales_history, _previous_appraisals, _building_improvement)\n",
        "                break\n",
        "          except:\n",
        "            print('Exception occured in checking termination for index', index)      \n",
        "            break\n",
        "          \n",
        "      print(index)\n",
        "      index = index+1\n",
        "#      if index == 5:\n",
        "#          break \n",
        "      if index %1000:\n",
        "        property_summary.to_csv('Property Summary.csv')\n",
        "        sales_history.to_csv('Sales History.csv')\n",
        "        previous_appraisals.to_csv('Previous Appraisals.csv')\n",
        "        building_improvement.to_csv('Building Improvement.csv')\n",
        "\n",
        "property_summary.to_csv('Property Summary.csv')\n",
        "sales_history.to_csv('Sales History.csv')\n",
        "previous_appraisals.to_csv('Previous Appraisals.csv')\n",
        "building_improvement.to_csv('Building Improvement.csv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5xKfU764or-",
        "colab_type": "code",
        "outputId": "827f25f6-b424-4202-8e74-b721728214b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    }
  ]
}